---
title: "ts gamma"
output: pdf_document
date: "2025-04-02"
---

```{r}
library(readr)
library(dplyr)
library(tidyverse)
library(lubridate)
library(parallel)
library(forecast)
library(ggplot2)
library(tidyr)



lincoln08 <- read_csv("NE_LINCOLN_2008.csv")
lincoln09 <- read_csv("NE_LINCOLN_2009.csv")
lincoln10 <- read_csv("NE_LINCOLN_2010.csv")
lincoln11 <- read_csv("NE_LINCOLN_2011.csv")
lincoln12 <- read_csv("NE_LINCOLN_2012.csv")
lincoln13 <- read_csv("NE_LINCOLN_2013.csv")
lincoln14 <- read_csv("NE_LINCOLN_2014.csv")
lincoln15 <- read_csv("NE_LINCOLN_2015.csv")
lincoln16 <- read_csv("NE_LINCOLN_2016.csv")
lincoln17 <- read_csv("NE_LINCOLN_2017.csv")
lincoln18 <- read_csv("NE_LINCOLN_2018.csv")
lincoln19 <- read_csv("NE_LINCOLN_2019.csv")
lincoln20 <- read_csv("NE_LINCOLN_2020.csv")
lincoln21 <- read_csv("NE_LINCOLN_2021.csv")
lincoln22 <- read_csv("NE_LINCOLN_2022.csv")
lincoln23 <- read_csv("NE_LINCOLN_2023.csv")
lincoln24 <- read_csv("NE_LINCOLN_2024.csv")
lincoln25 <- read_csv("NE_LINCOLN_2025 (1).csv")

```

Combine data
```{r}
all_data <- bind_rows(lincoln08, lincoln09, lincoln10, lincoln11, lincoln12,
                      lincoln13, lincoln14, lincoln15, lincoln16, lincoln17,
                      lincoln18, lincoln19, lincoln20, lincoln21, lincoln22,
                      lincoln23, lincoln24, lincoln25)
head(all_data)

```
```{r}
all_data_clean <- all_data %>%
  drop_na(`DOSE EQUIVALENT RATE (nSv/h)`)

```

```{r}
all_data_clean$`SAMPLE COLLECTION TIME` <- as.POSIXct(all_data_clean$`SAMPLE COLLECTION TIME`, 
                                                           format = "%m/%d/%Y %H:%M:%S")
plot.ts(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`)
```
```{r}
ts_data <- ts(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`, 
              start = c(2024), 
              frequency = 12)

```



```{r}
# decompose time series
ts_decomposition <- decompose(ts_data)

plot(ts_decomposition)

```

```{r}
# ARIMA model
arima_model <- auto.arima(ts_data, seasonal = TRUE)
summary(arima_model)

checkresiduals(arima_model)

# forecast next 12 months
forecast <- forecast(arima_model, h = 12)
summary(forecast)

plot(forecast, main = "Forecast for Next 12 Months", xlab = "Time", ylab = "Dose Equivalent Rate (nSv/h)")


```


```{r}
gamma_column <- 'DOSE EQUIVALENT RATE (nSv/h)'

# normal range is 6-83 nSv/h

# convert  column to a time series object (daily data)
gamma_ts <- ts(all_data_clean[[gamma_column]], frequency = 365, start = c(2008, 1))

# fit the seasonal and trend decomposition using LOESS (stlf) 
gamma_model_stlf <- stlf(gamma_ts)


# 2025 so far
forecast_days <- as.integer(as.Date("2025-03-26") - as.Date("2025-01-01"))

gamma_forecast_stlf <- forecast(gamma_model_stlf, h = forecast_days)
summary(gamma_forecast_stlf)


forecast_dates <- seq(as.Date("2025-01-01"), by = "day", length.out = length(gamma_forecast_stlf$mean))


# plot forecast for first three months, plot actual 2025 data and

plot(forecast_dates, gamma_forecast_stlf$mean, type = "l", col = "blue", 
     xlab = "Date", ylab = paste("Forecast for", gamma_column), 
     main = paste("Forecast for", gamma_column, "in 2025"))


plot(forecast_dates, gamma_forecast_stlf$mean, type = "l", col = "blue", 
     xlab = "Date", ylab = paste("Forecast for", gamma_column), 
     main = paste("Forecast for", gamma_column, "in 2025"), 
     ylim = range(c(gamma_forecast_stlf$lower[,2], gamma_forecast_stlf$upper[,2], gamma_forecast_stlf$mean)))
polygon(c(forecast_dates, rev(forecast_dates)), 
        c(gamma_forecast_stlf$lower[,2], rev(gamma_forecast_stlf$upper[,2])), 
        col = rgb(1, 0, 0, 0.2), border = NA)  #light red shaded area
lines(forecast_dates, gamma_forecast_stlf$mean, col = "blue", lwd = 2)
legend("topleft", legend = c("Forecast", "95% Confidence Interval"),
       col = c("blue", "pink"), lty = c(1, 1), lwd = c(2, 5), fill = c(NA, rgb(1, 0, 0, 0.2)))


plot.ts(lincoln25$`DOSE EQUIVALENT RATE (nSv/h)`)

```





linear regression
```{r}

all_data_clean <- all_data_clean %>% drop_na()
all_data_clean$STATUS <- as.factor(all_data_clean$STATUS)

numeric_columns <- c("DOSE EQUIVALENT RATE (nSv/h)", "GAMMA COUNT RATE R02 (CPM)", "GAMMA COUNT RATE R03 (CPM)", 
                     "GAMMA COUNT RATE R04 (CPM)", "GAMMA COUNT RATE R05 (CPM)", "GAMMA COUNT RATE R06 (CPM)", 
                     "GAMMA COUNT RATE R07 (CPM)", "GAMMA COUNT RATE R08 (CPM)", "GAMMA COUNT RATE R09 (CPM)")

all_data_clean[numeric_columns] <- scale(all_data_clean[numeric_columns])


# create lag variables
for(i in 1:3) {
  all_data_clean[paste("lag_DOSE_", i, sep = "")] <- dplyr::lag(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`, i)
}

# create rolling mean features 
all_data_clean$rolling_mean_DOSE <- zoo::rollmean(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`, 3, fill = NA)


```






```{r}
all_data_clean <- all_data %>%
  drop_na(`SAMPLE COLLECTION TIME`)
all_data_clean <- all_data_clean %>%
  drop_na(`DOSE EQUIVALENT RATE (nSv/h)`)

median_dose <- median(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`, na.rm = TRUE)
mad_dose <- mad(all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)`, constant = 1)

modified_z_scores <- 0.6745 * (all_data_clean$`DOSE EQUIVALENT RATE (nSv/h)` - median_dose) / mad_dose


worst_outliers <- all_data_clean %>% 
  mutate(modified_z_score = modified_z_scores) %>% 
  arrange(desc(abs(modified_z_score)))
```

```{r}
worst_outliers <- all_data_clean %>% 
  mutate(modified_z_score = modified_z_scores) %>% 
  arrange(desc(abs(modified_z_score))) %>% 
  head(100)

worst_outliers_over_time <- worst_outliers %>% 
  mutate(`SAMPLE COLLECTION TIME` = mdy_hms(`SAMPLE COLLECTION TIME`)) %>% 
  arrange(`SAMPLE COLLECTION TIME`)

ggplot(worst_outliers_over_time, aes(x = `SAMPLE COLLECTION TIME`, y = `DOSE EQUIVALENT RATE (nSv/h)`)) +
  geom_point() +
  labs(title = "100 Worst Outliers Over Time", x = "Sample Collection Time", y = "Dose Equivalent Rate (nSv/h)") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))


```


